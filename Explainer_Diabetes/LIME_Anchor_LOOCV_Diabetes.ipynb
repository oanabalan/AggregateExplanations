{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c2c3cff-f305-4b30-9011-25a17d9521ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'lime.lime_base' has no attribute 'explain_instance_with_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 172\u001b[0m\n\u001b[0;32m    170\u001b[0m explainer \u001b[38;5;241m=\u001b[39m lime\u001b[38;5;241m.\u001b[39mlime_tabular\u001b[38;5;241m.\u001b[39mLimeTabularExplainer(X_train, feature_names \u001b[38;5;241m=\u001b[39m X_featurenames, class_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo Diabetes\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDiabetes\u001b[39m\u001b[38;5;124m'\u001b[39m], feature_selection \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlasso_path\u001b[39m\u001b[38;5;124m\"\u001b[39m, discretize_continuous \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, discretizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquartile\u001b[39m\u001b[38;5;124m\"\u001b[39m, verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassification\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    171\u001b[0m exp \u001b[38;5;241m=\u001b[39m explainer\u001b[38;5;241m.\u001b[39mexplain_instance(X_test[\u001b[38;5;241m0\u001b[39m], model\u001b[38;5;241m.\u001b[39mpredict_proba)\n\u001b[1;32m--> 172\u001b[0m \u001b[43mlime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlime_base\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain_instance_with_data\u001b[49m()\n\u001b[0;32m    173\u001b[0m \u001b[38;5;66;03m#exp.show_in_notebook(show_table = True, show_all = True)\u001b[39;00m\n\u001b[0;32m    174\u001b[0m sys\u001b[38;5;241m.\u001b[39mstdout \u001b[38;5;241m=\u001b[39m old_stdout\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'lime.lime_base' has no attribute 'explain_instance_with_data'"
     ]
    }
   ],
   "source": [
    "import pandas as pd           # data mnipulation\n",
    "import numpy as np            # number manipulation/crunching\n",
    "import matplotlib.pyplot as plt  # plotting\n",
    "from sklearn.metrics import  accuracy_score, classification_report \n",
    "import openpyxl\n",
    "# Train Test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Random forest classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from anchor import utils\n",
    "from anchor import anchor_tabular\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "from collections import Counter\n",
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "diabetes = pd.read_csv(\"diabetes.csv\")\n",
    "diabetes['BloodPressure'] = diabetes['BloodPressure'].replace(to_replace=0,value=diabetes['BloodPressure'].median())\n",
    "diabetes['BMI'] = diabetes['BMI'].replace(to_replace=0,value=diabetes['BMI'].median())\n",
    "diabetes['Insulin'] = diabetes['Insulin'].replace(to_replace=0,value=diabetes['Insulin'].median())\n",
    "diabetes['Glucose'] = diabetes['Glucose'].replace(to_replace=0,value=diabetes['Glucose'].median())\n",
    "diabetes['SkinThickness'] = diabetes['SkinThickness'].replace(to_replace=0,value=diabetes['SkinThickness'].median())\n",
    "diabetes['BloodPressure'] = diabetes['BloodPressure'].replace(np.nan, 0)\n",
    "diabetes['BMI'] = diabetes['BMI'].replace(np.nan, 0)\n",
    "diabetes['Insulin'] = diabetes['Insulin'].replace(np.nan, 0)\n",
    "diabetes['Glucose'] = diabetes['Glucose'].replace(np.nan, 0)\n",
    "diabetes['SkinThickness'] = diabetes['SkinThickness'].replace(np.nan, 0)\n",
    "diabetes[\"Outcome\"].value_counts()\n",
    "\n",
    "Y = diabetes['Outcome']\n",
    "target_names=[\"No Diabetes\", \"Diabetes\"]\n",
    "X = diabetes[['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI','DiabetesPedigreeFunction', 'Age']]\n",
    "maximums = np.amax(np.array(X), axis=0)\n",
    "#X = diabetes.iloc[:,:-1].values\n",
    "X_featurenames = X.columns\n",
    "#X_featurenames = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI',\n",
    "        #'DiabetesPedigreeFunction', 'Age']\n",
    "\n",
    "# Split the data into train and test data:\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, shuffle = True)\n",
    "counter = Counter(Y)\n",
    "scale_pos_weight = counter[0] / counter[1]\n",
    "model = xgb.XGBClassifier(scale_pos_weight = scale_pos_weight)\n",
    "model.fit(X_train, Y_train)\n",
    "pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(Y_test, pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(classification_report(Y_test, pred, target_names=[\"No Diabetes\", \"Diabetes\"]))\n",
    "\n",
    "dataframe_columns_Anchors = []\n",
    "test_index = \"test_index\"\n",
    "dataframe_columns_Anchors.append(test_index)\n",
    "for feature in X_featurenames:\n",
    "    feature_lower_interval = feature + \"_lower_interval\"\n",
    "    feature_upper_interval = feature + \"_upper_interval\"\n",
    "    feature_rank = feature + \"_rank\"\n",
    "    dataframe_columns_Anchors.append(feature_lower_interval)\n",
    "    dataframe_columns_Anchors.append(feature_upper_interval)\n",
    "    dataframe_columns_Anchors.append(feature_rank)\n",
    "accuracy_classifier = \"accuracy_classifier\"\n",
    "precision = \"precision\"\n",
    "coverage = \"coverage\"\n",
    "prediction = \"prediction\"\n",
    "true_class = \"true_class\"\n",
    "dataframe_columns_Anchors.append(accuracy_classifier)\n",
    "dataframe_columns_Anchors.append(precision)\n",
    "dataframe_columns_Anchors.append(coverage)\n",
    "dataframe_columns_Anchors.append(prediction)\n",
    "dataframe_columns_Anchors.append(true_class)\n",
    "df_Anchors = pd.DataFrame(columns = dataframe_columns_Anchors)\n",
    "\n",
    "dataframe_columns_LIME = []\n",
    "test_index = \"test_index\"\n",
    "dataframe_columns_LIME.append(test_index)\n",
    "for feature in X_featurenames:\n",
    "    feature_lower_interval = feature + \"_lower_interval\"\n",
    "    feature_upper_interval = feature + \"_upper_interval\"\n",
    "    feature_probability = feature + \"_probability\"\n",
    "    feature_sign = feature + \"_sign\"\n",
    "    feature_rank = feature + \"_rank\"\n",
    "    dataframe_columns_LIME.append(feature_lower_interval)\n",
    "    dataframe_columns_LIME.append(feature_upper_interval)\n",
    "    dataframe_columns_LIME.append(feature_probability)\n",
    "    dataframe_columns_LIME.append(feature_sign)\n",
    "    dataframe_columns_LIME.append(feature_rank)\n",
    "intercept = \"intercept\"\n",
    "local_pred = \"local_pred\"\n",
    "probability_no_diabetes = \"probability_no_diabetes\"\n",
    "probability_diabetes = \"probability_diabetes\"\n",
    "accuracy_classifier = \"accuracy_classifier\"\n",
    "true_class = \"true_class\"\n",
    "dataframe_columns_LIME.append(intercept)\n",
    "dataframe_columns_LIME.append(local_pred)\n",
    "dataframe_columns_LIME.append(probability_no_diabetes)\n",
    "dataframe_columns_LIME.append(probability_diabetes)\n",
    "dataframe_columns_LIME.append(accuracy_classifier)\n",
    "dataframe_columns_LIME.append(true_class)\n",
    "df_LIME = pd.DataFrame(columns = dataframe_columns_LIME)\n",
    "\n",
    "cv = LeaveOneOut()\n",
    "\n",
    "number_iterations = 1\n",
    "for train_ix, test_ix in cv.split(X):\n",
    "    print(test_ix[0])\n",
    "    for count in range(number_iterations):\n",
    "        model = xgb.XGBClassifier(scale_pos_weight = scale_pos_weight)\n",
    "        X_train, X_test = X.to_numpy()[train_ix, :], X.to_numpy()[test_ix, :]\n",
    "        Y_train, Y_test = Y[train_ix], Y[test_ix]\n",
    "        model.fit(X_train, Y_train)  \n",
    "        explainer = anchor_tabular.AnchorTabularExplainer(class_names=target_names,\n",
    "                                                        feature_names=X_featurenames,train_data=X_train)\n",
    "        exp = explainer.explain_instance(X_test[0], model.predict, threshold=0.99)\n",
    "        list = exp.names()\n",
    "        row_Anchors = []\n",
    "        row_Anchors.append(test_ix[0])\n",
    "        for feature in X_featurenames:\n",
    "            ok = 0\n",
    "            for j in range(len(list)):\n",
    "                if list[j].find(feature) != -1 :\n",
    "                    ok = 1\n",
    "                    #print(list[j])\n",
    "                    rank = j + 1\n",
    "                    if list[j].count('.') == 2:\n",
    "                        lower_interval = list[j][0 : list[j].find('<')]\n",
    "                        upper_interval = list[j][list[j].find('=') + 2 : len(list[j]) + 1]\n",
    "                    elif list[j].count('.') == 1 and list[j].find('<') != -1:\n",
    "                        lower_interval = 0\n",
    "                        if(list[j].find('=') != -1):\n",
    "                            upper_interval = list[j][list[j].find('=') + 2 : len(list[j]) + 1]\n",
    "                        else:\n",
    "                            upper_interval = list[j][list[j].find('<') + 2 : len(list[j]) + 1]\n",
    "                    elif list[j].count('.') == 1 and list[j].find('>') != -1:\n",
    "                        upper_interval = maximums[X_featurenames.to_list().index(feature)]\n",
    "                        if(list[j].find('=') != -1):\n",
    "                            lower_interval = list[j][list[j].find('=') + 2 : len(list[j]) + 1]\n",
    "                        else:\n",
    "                            lower_interval = list[j][list[j].find('>') + 2 : len(list[j]) + 1]\n",
    "            if ok == 0:\n",
    "                lower_interval = -1\n",
    "                upper_interval = -1\n",
    "                rank = -1\n",
    "            #print(lower_interval)\n",
    "            #print(upper_interval)\n",
    "            #print(rank)\n",
    "            row_Anchors.append(lower_interval)\n",
    "            row_Anchors.append(upper_interval)\n",
    "            row_Anchors.append(rank)\n",
    "        pred = model.predict(X_test)\n",
    "        accuracy_classifier = accuracy_score(Y_test, pred)\n",
    "        precision = exp.precision()\n",
    "        coverage = exp.coverage()\n",
    "        prediction =  explainer.class_names[model.predict(X_test[0].reshape(1, -1))[0]]\n",
    "        true_class = target_names[Y_test[test_ix[0]]]\n",
    "        row_Anchors.append(accuracy_classifier)\n",
    "        row_Anchors.append(precision)\n",
    "        row_Anchors.append(coverage)\n",
    "        row_Anchors.append(prediction)\n",
    "        row_Anchors.append(true_class)\n",
    "        #print(row)\n",
    "        #print(df)\n",
    "        df_Anchors.loc[test_ix[0] * number_iterations + count] = row_Anchors\n",
    "        #print(df)\n",
    "        #-----------------------------------------------------------------\n",
    "        old_stdout = sys.stdout # backup current stdout\n",
    "        sys.stdout = open(os.devnull, \"w\")\n",
    "        explainer = lime.lime_tabular.LimeTabularExplainer(X_train, feature_names = X_featurenames, class_names = ['No Diabetes', 'Diabetes'], feature_selection = \"lasso_path\", discretize_continuous = True, discretizer = \"quartile\", verbose = True, mode = 'classification')\n",
    "        exp = explainer.explain_instance(X_test[0], model.predict_proba)\n",
    "        #exp.show_in_notebook(show_table = True, show_all = True)\n",
    "        sys.stdout = old_stdout\n",
    "        list = exp.as_list()\n",
    "        print(list)\n",
    "        print(exp.intercept)\n",
    "        print(exp.local_pred)\n",
    "        intercept = exp.intercept[1]\n",
    "        local_pred = exp.local_pred[0]\n",
    "        row_LIME = []\n",
    "        row_LIME.append(test_ix[0])\n",
    "        for feature in X_featurenames:\n",
    "            upper_interval = -1\n",
    "            lower_interval = -1\n",
    "            probability = -1\n",
    "            sign = -1\n",
    "            rank = -1\n",
    "            for j in range(len(X_featurenames)):\n",
    "                if j < len(list) and list[j] is not None and list[j][0].find(feature) != -1 :\n",
    "                    probability = list[j][1]\n",
    "                    rank = j + 1\n",
    "                    if probability > 0 :\n",
    "                        sign = \"positive\"\n",
    "                    else :\n",
    "                        sign = \"negative\"\n",
    "                    if list[j][0].count('.') == 2:\n",
    "                        lower_interval = list[j][0][0 : list[j][0].find('<')]\n",
    "                        upper_interval = list[j][0][list[j][0].find('=') + 2 : len(list[j][0]) + 1]\n",
    "                    elif list[j][0].count('.') == 1 and list[j][0].find('<') != -1:\n",
    "                        lower_interval = 0\n",
    "                        if(list[j][0].find('=') != -1):\n",
    "                            upper_interval = list[j][0][list[j][0].find('=') + 2 : len(list[j][0]) + 1]\n",
    "                        else:\n",
    "                            upper_interval = list[j][0][list[j][0].find('<') + 2 : len(list[j][0]) + 1]\n",
    "                    elif list[j][0].count('.') == 1 and list[j][0].find('>') != -1:\n",
    "                        upper_interval = maximums[X_featurenames.to_list().index(feature)]\n",
    "                        if(list[j][0].find('=') != -1):\n",
    "                            lower_interval = list[j][0][list[j][0].find('=') + 2 : len(list[j][0]) + 1]\n",
    "                        else:\n",
    "                            lower_interval = list[j][0][list[j][0].find('>') + 2 : len(list[j][0]) + 1]\n",
    "                    #print(lower_interval)\n",
    "                    #print(upper_interval)\n",
    "            row_LIME.append(lower_interval)\n",
    "            row_LIME.append(upper_interval)\n",
    "            row_LIME.append(probability)\n",
    "            row_LIME.append(sign)\n",
    "            row_LIME.append(rank)\n",
    "        probability_no_diabetes = model.predict_proba([X_test[0]])[0,0]\n",
    "        probability_diabetes = model.predict_proba([X_test[0]])[0,1]\n",
    "        pred = model.predict(X_test)\n",
    "        accuracy_classifier = accuracy_score(Y_test, pred)\n",
    "        true_class = target_names[Y_test[test_ix[0]]]\n",
    "        row_LIME.append(intercept)\n",
    "        row_LIME.append(local_pred)\n",
    "        row_LIME.append(probability_no_diabetes)\n",
    "        row_LIME.append(probability_diabetes)\n",
    "        row_LIME.append(accuracy_classifier)\n",
    "        row_LIME.append(true_class)\n",
    "        #print(row)\n",
    "        df_LIME.loc[test_ix[0] * number_iterations + count] = row_LIME\n",
    "\n",
    "df_Anchors.to_excel(\"outputDiabetesAnchorLOOCV.xlsx\")\n",
    "df_LIME.to_excel(\"outputDiabetesLIMELOOCV.xlsx\")\n",
    "\n",
    "# print('Anchor: %s' % (' AND '.join(exp.names())))\n",
    "# print('Precision: %.2f' % exp.precision())\n",
    "# print('Coverage: %.2f' % exp.coverage())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5dfb79-bf09-445b-9dd5-f826c8e3c599",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
