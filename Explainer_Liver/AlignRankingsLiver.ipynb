{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f075ada-6f7d-4d8c-8117-0867f6e2fc3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\STUDENT018\\AppData\\Local\\Temp\\ipykernel_10036\\998644996.py:189: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0.1' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_Anchor.loc[i] = list\n"
     ]
    }
   ],
   "source": [
    "import openpyxl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "feature_names = ['Age', 'TB', 'DB', 'Alkphos', 'Sgpt','TP', 'ALB', 'AG_Ratio', 'Gender']\n",
    "noOfIterations = 100\n",
    "\n",
    "def generateRankings(feature_names):\n",
    "    dataframe = openpyxl.load_workbook(\"outputLiverKernelShapLOOCV_1.xlsx\")\n",
    "    sheet = dataframe.active\n",
    "   \n",
    "    list = []\n",
    "    for i in range(len(feature_names)):\n",
    "        list_feature = []\n",
    "        list.append(list_feature)\n",
    "    \n",
    "    df_KernelShap = pd.DataFrame()\n",
    "    \n",
    "    for i, row in enumerate(sheet):\n",
    "        step = 7\n",
    "        if i == 0: \n",
    "            continue\n",
    "        for k in range(len(feature_names)):\n",
    "            if k == 0:\n",
    "                list[k].append(row[4].value)\n",
    "            else:\n",
    "                list[k].append(row[step].value)\n",
    "                step = step + 3\n",
    "    dict = {}\n",
    "    for i in range(len(feature_names)):\n",
    "        new_data = {feature_names[i]: list[i]} \n",
    "        dict.update(new_data)\n",
    "        \n",
    "    df_KernelShap = pd.DataFrame(dict)\n",
    "    \n",
    "    for i in range(len(df_KernelShap)):\n",
    "        list = []\n",
    "        for j in range(len(feature_names)):\n",
    "            if df_KernelShap.iloc[i, j] != 0 :\n",
    "                count = 0\n",
    "                for k in range(len(feature_names)):\n",
    "                   if df_KernelShap.iloc[i, k] > df_KernelShap.iloc[i, j]:\n",
    "                        count = count + 1\n",
    "                count = count + 1\n",
    "                list.append(count)\n",
    "            else:\n",
    "                list.append(0.1)\n",
    "        df_KernelShap.loc[i] = list\n",
    "    \n",
    "    df_KernelShap.to_excel(\"rankingsLiverKernelShap.xlsx\")\n",
    "   \n",
    "    #################################################################\n",
    "    dataframe = openpyxl.load_workbook(\"outputLiverTreeShapLOOCV_1.xlsx\")\n",
    "    sheet = dataframe.active\n",
    "   \n",
    "    list = []\n",
    "    for i in range(len(feature_names)):\n",
    "        list_feature = []\n",
    "        list.append(list_feature)\n",
    "    \n",
    "    df_TreeShap = pd.DataFrame()\n",
    "    \n",
    "    for i, row in enumerate(sheet):\n",
    "        step = 7\n",
    "        if i == 0: \n",
    "            continue\n",
    "        for k in range(len(feature_names)):\n",
    "            if k == 0:\n",
    "                list[k].append(row[4].value)\n",
    "            else:\n",
    "                list[k].append(row[step].value)\n",
    "                step = step + 3          \n",
    "          \n",
    "    dict = {}\n",
    "    for i in range(len(feature_names)):\n",
    "        new_data = {feature_names[i]: list[i]} \n",
    "        dict.update(new_data)\n",
    "        \n",
    "    df_TreeShap = pd.DataFrame(dict)\n",
    "   \n",
    "    for i in range(len(df_TreeShap)):\n",
    "        list = []\n",
    "        for j in range(len(feature_names)):\n",
    "            if df_TreeShap.iloc[i, j] != 0 :\n",
    "                count = 0\n",
    "                for k in range(len(feature_names)):\n",
    "                   if df_TreeShap.iloc[i, k] > df_TreeShap.iloc[i, j]:\n",
    "                        count = count + 1\n",
    "                count = count + 1\n",
    "                list.append(count)\n",
    "            else:\n",
    "                list.append(0.1)\n",
    "        df_TreeShap.loc[i] = list\n",
    "    \n",
    "    df_TreeShap.to_excel(\"rankingsLiverTreeShap.xlsx\")    \n",
    "\n",
    "    ############################################################################\n",
    "    dataframe = openpyxl.load_workbook(\"outputLiverLIMELOOCV_100.xlsx\")\n",
    "    sheet = dataframe.active\n",
    "   \n",
    "    list = []\n",
    "    for i in range(len(feature_names)):\n",
    "        list_feature = []\n",
    "        list.append(list_feature)\n",
    "    \n",
    "    df_LIME = pd.DataFrame()\n",
    "    \n",
    "    for i, row in enumerate(sheet):\n",
    "        step = 11\n",
    "        if i == 0: \n",
    "            continue\n",
    "        for k in range(len(feature_names)):\n",
    "            if k == 0:\n",
    "                list[k].append(row[6].value)\n",
    "            else:\n",
    "                list[k].append(row[step].value)\n",
    "                step = step + 5            \n",
    "            \n",
    "    dict = {}\n",
    "    for i in range(len(feature_names)):\n",
    "        new_data = {feature_names[i]: list[i]} \n",
    "        dict.update(new_data)\n",
    "        \n",
    "    df_LIME = pd.DataFrame(dict)\n",
    "   \n",
    "    for i in range(len(df_LIME)):\n",
    "        list = []\n",
    "        for j in range(len(feature_names)):\n",
    "            if df_LIME.iloc[i, j] != 0 :\n",
    "                count = 0\n",
    "                for k in range(len(feature_names)):\n",
    "                   if df_LIME.iloc[i, k] > df_LIME.iloc[i, j]:\n",
    "                        count = count + 1\n",
    "                count = count + 1\n",
    "                list.append(count)\n",
    "            else:\n",
    "                list.append(0.1)\n",
    "        df_LIME.loc[i] = list\n",
    "    \n",
    "    df_LIME.to_excel(\"rankingsLiverLIME.xlsx\")\n",
    "    ################################################################\n",
    "    dataframe = openpyxl.load_workbook(\"outputLiverAnchorLOOCV_100_99thr.xlsx\")\n",
    "    sheet = dataframe.active\n",
    "   \n",
    "    list = []\n",
    "    for i in range(len(feature_names)):\n",
    "        list_feature = []\n",
    "        list.append(list_feature)\n",
    "    \n",
    "    df_Anchor = pd.DataFrame()\n",
    "    \n",
    "    for i, row in enumerate(sheet):\n",
    "        step = 7\n",
    "        if i == 0: \n",
    "            continue\n",
    "        for k in range(len(feature_names)):\n",
    "            if k == 0:\n",
    "                val = row[4].value\n",
    "                if val == -1:\n",
    "                    val = 0\n",
    "                list[k].append(val)\n",
    "            else:\n",
    "                val = row[step].value\n",
    "                if val == -1:\n",
    "                   val = 0 \n",
    "                list[k].append(val)\n",
    "                step = step + 3\n",
    "        \n",
    "    dict = {}\n",
    "    for i in range(len(feature_names)):\n",
    "        new_data = {feature_names[i]: list[i]} \n",
    "        dict.update(new_data)\n",
    "        \n",
    "    df_Anchor = pd.DataFrame(dict)\n",
    "  \n",
    "    for i in range(len(df_Anchor)):\n",
    "        list = []\n",
    "        for j in range(len(feature_names)):\n",
    "            if df_Anchor.iloc[i, j] != 0 :\n",
    "                count = 0\n",
    "                for k in range(len(feature_names)):\n",
    "                   if df_Anchor.iloc[i, k] > df_Anchor.iloc[i, j]:\n",
    "                        count = count + 1\n",
    "                count = count + 1\n",
    "                list.append(count)\n",
    "            else:\n",
    "                list.append(0.1)\n",
    "        df_Anchor.loc[i] = list\n",
    "    \n",
    "    df_Anchor.to_excel(\"rankingsLiverAnchor.xlsx\")\n",
    "\n",
    "def stackRowsColumns(M, noOfRows, noOfColumns):\n",
    "    pos = [0] * noOfRows\n",
    "    for i in range (0, noOfRows):\n",
    "        pos[i] = i\n",
    "    \n",
    "    for i in range(1, noOfRows):\n",
    "        wsim = [0] * noOfRows\n",
    "        for j in range(i, noOfRows):\n",
    "            for k in range(0, i):\n",
    "                A = M.loc[k]\n",
    "                B = M.loc[j]\n",
    "                wsim[j] = wsim[j] + (1 / ( i - k)) * np.dot(A,B)/(norm(A)*norm(B))\n",
    "        max_value = max(wsim)\n",
    "        max_index = wsim.index(max_value)\n",
    "        aux = M.loc[max_index]\n",
    "        M.loc[max_index] = M.loc[i]\n",
    "        M.loc[i] = aux\n",
    "        aux = pos[max_index]\n",
    "        pos[max_index] = pos[i]\n",
    "        pos[i] = aux\n",
    "\n",
    "    \n",
    "    for i in range(1, noOfColumns):\n",
    "        wsim = [0] * noOfColumns\n",
    "        for j in range(i, noOfColumns):\n",
    "            for k in range(0, i):\n",
    "                A = M.loc[k]\n",
    "                B = M.loc[j]\n",
    "                wsim[j] = wsim[j] + (1 / ( i - k)) * np.dot(A,B)/(norm(A)*norm(B))\n",
    "        max_value = max(wsim)\n",
    "        max_index = wsim.index(max_value)\n",
    "        aux = M.loc[max_index]\n",
    "        M.loc[max_index] = M.loc[i]\n",
    "        M.loc[i] = aux\n",
    "    return pos, M\n",
    "\n",
    "def cosineSimilarity(A, B):\n",
    "    return np.dot(A,B)/(norm(A)*norm(B))\n",
    "\n",
    "def similarityCase(M, i):\n",
    "    s = 0\n",
    "    k = i - 1\n",
    "    for j in range (1, k + 1):\n",
    "        s = s + cosineSimilarity(M.loc[i], M.loc[i - j]) * (1 / j)\n",
    "    return s\n",
    "\n",
    "def similarityMatrix(M, noOfRows):\n",
    "    s = 0\n",
    "    for i in range(1, noOfRows):\n",
    "        s = s + similarityCase(M, i)\n",
    "    s = s / (noOfRows - 1)\n",
    "    return s\n",
    "\n",
    "def GlobalAlign(MSP, MS, noOfRows):\n",
    "    if similarityMatrix(MSP, noOfRows) >  similarityMatrix(MS, noOfRows):\n",
    "        max = similarityMatrix(MSP, noOfRows)\n",
    "        min = similarityMatrix(MS, noOfRows)\n",
    "    else:\n",
    "        max = similarityMatrix(MS, noOfRows)\n",
    "        min = similarityMatrix(MSP, noOfRows)\n",
    "    return min / max\n",
    "    #return similarityMatrix(MSP, noOfRows) / similarityMatrix(MS, noOfRows)\n",
    "\n",
    "\n",
    "def createMSP(MP, MS, noOfRows):\n",
    "    MS_copy = MS.copy(deep = True)\n",
    "    MP_copy = MP.copy(deep = True)\n",
    "    posS, MS_copy = stackRowsColumns(MS_copy, noOfRows, len(feature_names))\n",
    "    posP, MP_copy = stackRowsColumns(MP_copy, noOfRows, len(feature_names))\n",
    "    # MSP = pd.DataFrame(columns = feature_names)\n",
    "    # for i in range(0, noOfRows):\n",
    "    #     MSP.loc[posP[i]] = MS_copy.loc[posS[i]]\n",
    "    return GlobalAlign(MP_copy, MS_copy, noOfRows)\n",
    "\n",
    "generateRankings(feature_names)\n",
    "# df_KernelShap = pd.read_excel('rankingsKernelShap.xlsx')\n",
    "# df_KernelShap = df_KernelShap[df_KernelShap.columns[1:]]\n",
    "# df_TreeShap = pd.read_excel('rankingsTreeShap.xlsx')\n",
    "# df_TreeShap = df_TreeShap[df_TreeShap.columns[1:]]\n",
    "# df_LIME = pd.read_excel('rankingsLIME.xlsx')\n",
    "# df_LIME = df_LIME[df_LIME.columns[1:]]\n",
    "# df_Anchor = pd.read_excel('rankingsAnchor.xlsx')\n",
    "# df_Anchor = df_Anchor[df_Anchor.columns[1:]]\n",
    "\n",
    "\n",
    "# results = pd.DataFrame(columns = ['AA', 'AL', 'AS', 'LA', 'LL', 'LS', 'SA', 'SL', 'SS'])\n",
    "# noOfInstances = df_KernelShap.shape[0]\n",
    "\n",
    "# for instance in range(0, noOfInstances):\n",
    "#     result = []\n",
    "#     data_Shap = []\n",
    "#     for i in range(int(noOfIterations / 2)):\n",
    "#         data_Shap.append(df_KernelShap.loc[instance].values.flatten().tolist())\n",
    "#         data_Shap.append(df_TreeShap.loc[instance].values.flatten().tolist())\n",
    "#     M_Shap  = pd.DataFrame(data_Shap, columns = feature_names)\n",
    "    \n",
    "#     data_LIME = []\n",
    "#     for i in range(noOfIterations):\n",
    "#         data_LIME.append(df_LIME.loc[instance * noOfIterations + i].values.flatten().tolist())\n",
    "#     M_LIME  = pd.DataFrame(data_LIME, columns = feature_names)\n",
    "    \n",
    "#     data_Anchor = []\n",
    "#     for i in range(noOfIterations):\n",
    "#         data_Anchor.append(df_Anchor.loc[instance * noOfIterations + i].values.flatten().tolist())\n",
    "#     M_Anchor  = pd.DataFrame(data_Anchor, columns = feature_names)  \n",
    "\n",
    "#     MP = M_Anchor\n",
    "#     MS = M_Anchor\n",
    "#     result.append(createMSP(MP, MS, noOfIterations))\n",
    "#     MP = M_Anchor\n",
    "#     MS = M_LIME\n",
    "#     result.append(createMSP(MP, MS, noOfIterations))\n",
    "#     MP = M_Anchor\n",
    "#     MS = M_Shap\n",
    "#     result.append(createMSP(MP, MS, noOfIterations))\n",
    "#     MP = M_LIME\n",
    "#     MS = M_Anchor\n",
    "#     result.append(createMSP(MP, MS, noOfIterations))\n",
    "#     MP = M_LIME\n",
    "#     MS = M_LIME\n",
    "#     result.append(createMSP(MP, MS, noOfIterations))\n",
    "#     MP = M_LIME\n",
    "#     MS = M_Shap\n",
    "#     result.append(createMSP(MP, MS, noOfIterations))\n",
    "#     MP = M_Shap\n",
    "#     MS = M_Anchor\n",
    "#     result.append(createMSP(MP, MS, noOfIterations))\n",
    "#     MP = M_Shap\n",
    "#     MS = M_LIME\n",
    "#     result.append(createMSP(MP, MS, noOfIterations))\n",
    "#     MP = M_Shap\n",
    "#     MS = M_Shap\n",
    "#     result.append(createMSP(MP, MS, noOfIterations))\n",
    "#     print(result)\n",
    "#     results.loc[instance] = result\n",
    "\n",
    "# print(results)\n",
    "# results.to_excel(\"resultsLiverMPMS_MinMax.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6e9baa-e4be-4dec-af53-c7561a895a2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
